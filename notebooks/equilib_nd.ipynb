{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bacdc0df",
   "metadata": {},
   "source": [
    "# Equilibrium in Multiple Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a9ece4",
   "metadata": {},
   "source": [
    "#### Author: [John Stachurski](http://johnstachurski.net/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d81707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import exp, sqrt\n",
    "from numba import njit\n",
    "from scipy.optimize import newton, root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfa1750",
   "metadata": {},
   "source": [
    "In this notebook we expore the problem of computing market equilibrium in a multivariate setting, with many goods.\n",
    "\n",
    "As a first step, we set up and solve a two-good problem.  \n",
    "\n",
    "Then we shift to higher dimensions.  \n",
    "\n",
    "We will show how gradient-based equation solvers can handle high dimensional problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d102ae",
   "metadata": {},
   "source": [
    "## Two Goods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae9b8af",
   "metadata": {},
   "source": [
    "We first consider a market for two related products, good 0 and good 1, with price vector $p = (p_0, p_1)$.\n",
    "\n",
    "Supply of good $i$ at price $p$ is \n",
    "\n",
    "$$ q^s_i (p) = b_i \\sqrt{p_i} $$\n",
    "\n",
    "Demand of good $i$ at price $p$ is\n",
    "\n",
    "$$ q^d_i (p) = \\exp(-a_{i0} p_0 - a_{i1} p_1) + c_i$$\n",
    "\n",
    "Here $c_i, b_i$ and $a_{ij}$ are parameters.  \n",
    "\n",
    "The excess demand functions are\n",
    "\n",
    "$$ e_i(p) = q^d_i(p) - q^s_i(p), \\qquad i = 0, 1 $$\n",
    "\n",
    "An equilibrium price vector $p^*$ is one where $e_i(p^*) = 0$.  \n",
    "\n",
    "We set\n",
    "\n",
    "$$ \n",
    "    A = \\begin{pmatrix}\n",
    "            a_{00} & a_{01} \\\\\n",
    "            a_{10} & a_{11}\n",
    "        \\end{pmatrix},\n",
    "            \\qquad \n",
    "    b = \\begin{pmatrix}\n",
    "            b_0 \\\\\n",
    "            b_1\n",
    "        \\end{pmatrix}\n",
    "    \\qquad \\text{and} \\qquad\n",
    "    c = \\begin{pmatrix}\n",
    "            c_0 \\\\\n",
    "            c_1\n",
    "        \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e325053",
   "metadata": {},
   "source": [
    "## Graphical Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309409be",
   "metadata": {},
   "source": [
    "Since our problem is only two dimensional, we can use graphical analysis to visualize and help understand the problem.\n",
    "\n",
    "Our first step is to define the excess demand function\n",
    "\n",
    "$$ e(p) = \n",
    "    \\begin{pmatrix}\n",
    "    e_0(p) \\\\\n",
    "    e_1(p)\n",
    "    \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "The function below does the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afedfa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def e(p, A, b, c):\n",
    "    return exp(- A @ p) + c - b * sqrt(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e2d87",
   "metadata": {},
   "source": [
    "Our default parameter values will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a85ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ((0.5, 0.4),\n",
    "     (0.8, 0.2))\n",
    "A = np.asarray(A)\n",
    "b = np.ones(2)\n",
    "c = np.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e8e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e((1.0, 0.5), A, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35eba8c",
   "metadata": {},
   "source": [
    "Next we plot the two functions $e_0$ and $e_1$ on a grid of $(p_0, p_1)$ values, using contour surfaces and lines.\n",
    "\n",
    "We will use the following function to build the contour plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_excess_demand(ax, good=0, grid_size=100, grid_max=4, surface=True):\n",
    "    p_grid = np.linspace(0, grid_max, grid_size)\n",
    "    z = np.empty((100, 100))\n",
    "\n",
    "    for i, p_0 in enumerate(p_grid):\n",
    "        for j, p_1 in enumerate(p_grid):\n",
    "            z[i, j] = e((p_0, p_1), A, b, c)[good]\n",
    "\n",
    "    if surface:\n",
    "        cs1 = ax.contourf(p_grid, p_grid, z.T, alpha=0.5)\n",
    "        plt.colorbar(cs1, ax=ax, format=\"%.6f\")\n",
    "\n",
    "    ctr1 = ax.contour(p_grid, p_grid, z.T, levels=[0.0])\n",
    "    plt.clabel(ctr1, inline=1, fontsize=13)\n",
    "    ax.set_xlabel(\"$p_0$\")\n",
    "    ax.set_ylabel(\"$p_1$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6bb41",
   "metadata": {},
   "source": [
    "Here's our plot of $e_0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20070642",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5.7))\n",
    "plot_excess_demand(ax, good=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51971a66",
   "metadata": {},
   "source": [
    "We see the black contour line of zero, which tells us when $e_0(p)=0$.\n",
    "\n",
    "For a price vector $p$ such that $e_0(p) = 0$, we know that good $0$ is in equilibrium (demand equals supply)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955e206f",
   "metadata": {},
   "source": [
    "Here's our plot of $e_1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3cfd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5.7))\n",
    "plot_excess_demand(ax, good=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694f532a",
   "metadata": {},
   "source": [
    "Now the black contour line of zero tells us when $e_1(p)=0$ (i.e., good $1$ is in equilibrium)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b122a",
   "metadata": {},
   "source": [
    "If these two contour lines cross at some vector $p^*$, then $p^*$ is an equilibrium price vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ea64f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5.7))\n",
    "for good in (0, 1):\n",
    "    plot_excess_demand(ax, good=good, surface=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d45f0",
   "metadata": {},
   "source": [
    "It seems there is an equilibrium close to $p = (1.6, 1.5)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e75812",
   "metadata": {},
   "source": [
    "## Using a Multidimensional Root Finder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d92d0b",
   "metadata": {},
   "source": [
    "To solve for $p^*$ more precisely, we use `root`, a root-finding algorithm from `scipy.optimize`.\n",
    "\n",
    "We supply $p = (1, 1)$ as our initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e0296",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_p = np.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc54dc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = root(lambda p: e(p, A, b, c), init_p, method='hybr')\n",
    "p = solution.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e4bfd9",
   "metadata": {},
   "source": [
    "Here's the resulting value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34699d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c3d4fa",
   "metadata": {},
   "source": [
    "This looks close to our guess from observing the figure.  We can plug it back into $e$ to test that $e(p) \\approx 0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f40c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(e(p, A, b, c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc4d660",
   "metadata": {},
   "source": [
    "This is indeed a very small error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c21f95",
   "metadata": {},
   "source": [
    "In most cases, for root-finding algorithms applied to smooth functions, supplying the Jacobian of the function leads to better convergence properties.  \n",
    "\n",
    "In this case we manually calculate the elements of the Jacobian\n",
    "\n",
    "$$\n",
    "    J(p) = \n",
    "    \\begin{pmatrix}\n",
    "        \\frac{\\partial e_0}{\\partial p_0}(p) & \\frac{\\partial e_0}{\\partial p_1}(p) \\\\\n",
    "        \\frac{\\partial e_1}{\\partial p_0}(p) & \\frac{\\partial e_1}{\\partial p_1}(p)\n",
    "    \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "and supply the Jacobian as a function, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1101d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def jacobian(p, A, b, c):\n",
    "    p_0, p_1 = p\n",
    "    a_00, a_01 = A[0, :]\n",
    "    a_10, a_11 = A[1, :]\n",
    "    j_00 = -a_00 * exp(-a_00 * p_0) - (b[0]/2) * p_0**(-1/2)\n",
    "    j_01 = -a_01 * exp(-a_01 * p_1)\n",
    "    j_10 = -a_10 * exp(-a_10 * p_0)\n",
    "    j_11 = -a_11 * exp(-a_11 * p_1) - (b[1]/2) * p_1**(-1/2)\n",
    "    J = [[j_00, j_01],\n",
    "         [j_10, j_11]]\n",
    "    return np.array(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3746d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = root(lambda p: e(p, A, b, c),\n",
    "                init_p, \n",
    "                jac=lambda p: jacobian(p, A, b, c), \n",
    "                method='hybr')\n",
    "p = solution.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71828cb7",
   "metadata": {},
   "source": [
    "Now the solution is even more accurate (although, in this low-dimensional problem, the difference is quite small):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dbaa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(e(p, A, b, c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78503a57",
   "metadata": {},
   "source": [
    "## High-Dimensional Problems\n",
    "\n",
    "Our next step is to investigate a high-dimensional version of the market described above.  This market consists of 5,000 goods.  \n",
    "\n",
    "The excess demand function is essentially the same, but now the matrix $A$ is $5000 \\times 5000$ and the parameter vectors $b$ and $c$ are $5000 \\times 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2a35e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 5000\n",
    "\n",
    "# Create a random matrix A and normalize the rows to sum to one\n",
    "A = np.random.rand(dim, dim)\n",
    "A = np.asarray(A)\n",
    "s = np.sum(A, axis=0)\n",
    "A = A / s\n",
    "\n",
    "# Set up b and c\n",
    "b = np.ones(dim)\n",
    "c = np.ones(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2547bf07",
   "metadata": {},
   "source": [
    "Here's the same demand function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324d0457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def e(p, A, b, c):\n",
    "    return exp(- A @ p) + c - b * sqrt(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3649ba06",
   "metadata": {},
   "source": [
    "For our particular case, calculating and supplying the Jacobian is not too hard, but you can imagine that it can be very tedious when the functions get more complicated.  \n",
    "\n",
    "So let's see how we go when the Jacobian is not supplied.\n",
    "\n",
    "Here's our initial condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aff8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_p = np.ones(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad27d61f",
   "metadata": {},
   "source": [
    "Now we call `root` again.\n",
    "\n",
    "**Warning**: The next line of code takes several minutes to run on a standard laptop or desktop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da8153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "solution = root(lambda p: e(p, A, b, c), init_p, method='hybr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd1716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = solution.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16089e0c",
   "metadata": {},
   "source": [
    "Although it takes a long time to run, the answer is correct up to a high degree of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d529eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(e(p, A, b, c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909540db",
   "metadata": {},
   "source": [
    "## Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb44b5",
   "metadata": {},
   "source": [
    "To produce a faster and more efficient implementation, we shift to using JAX.\n",
    "\n",
    "With JAX, we get three big advantages:\n",
    "\n",
    "1. We can use JAX's automatic differentiation to compute the Jacobian easily and efficiently.\n",
    "2. JAX can parallelize the problem.\n",
    "3. JAX can dispatch to the GPU, if configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea1bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ffab3b",
   "metadata": {},
   "source": [
    "We set up the same demand function, replacing `np` with `jnp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def e(p, A, b, c):\n",
    "    return jnp.exp(- jnp.dot(A, p)) + c - b * jnp.sqrt(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16264615",
   "metadata": {},
   "source": [
    "We are going to try to compute the equilibrium price using the multivariate version of Newton's method, which means iterating on the equation\n",
    "\n",
    "$$ p_{n+1} = p_n - J(p_n)^{-1} e(p_n) $$\n",
    "\n",
    "starting from some initial guess of the price vector $p_0$.  (Here $J$ is the Jacobian of $e$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b17ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(f, x_0, tol=1e-5):\n",
    "    f_prime = jax.grad(f)\n",
    "    def q(x):\n",
    "        return x - jnp.linalg.solve(jax.jacobian(f)(x), f(x))\n",
    "\n",
    "    error = tol + 1\n",
    "    x = x_0\n",
    "    while error > tol:\n",
    "        y = q(x)\n",
    "        error = jnp.linalg.norm(x - y)\n",
    "        x = y\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8f3150",
   "metadata": {},
   "source": [
    "Let's see whether this can solve the problem and how long it takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8645c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p = newton(lambda p: e(p, A, b, c), init_p).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e8b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p = newton(lambda p: e(p, A, b, c), init_p).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3e0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(e(p, A, b, c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366e2612",
   "metadata": {},
   "source": [
    "We still have a solution that's very accurate and the compute time is massively reduced (assuming JAX is connecting to a GPU).\n",
    "\n",
    "\n",
    "### Exercise \n",
    "\n",
    "Write a simplified version of the `newton` function above that works for\n",
    "scalar functions (real inputs and real outputs).\n",
    "\n",
    "Test it on this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1b3ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: jnp.sin(4 * (x - 1/4)) + x + x**20 - 1\n",
    "x = jnp.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, f(x), label='$f(x)$')\n",
    "ax.axhline(ls='--', c='k')\n",
    "ax.set_xlabel('$x$', fontsize=12)\n",
    "ax.set_ylabel('$f(x)$', fontsize=12)\n",
    "ax.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b93b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f16ddd",
   "metadata": {},
   "source": [
    "solution below\n",
    "\n",
    "solution below\n",
    "\n",
    "solution below\n",
    "\n",
    "solution below\n",
    "\n",
    "solution below\n",
    "\n",
    "solution below\n",
    "\n",
    "solution below\n",
    "\n",
    "solution below\n",
    "\n",
    "solution below\n",
    "\n",
    "solution below\n",
    "\n",
    "solution below\n",
    "\n",
    "solution below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b69b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(f, x_0, tol=1e-5):\n",
    "    f_prime = jax.grad(f)\n",
    "    def q(x):\n",
    "        return x - f(x) / f_prime(x)\n",
    "\n",
    "    error = tol + 1\n",
    "    x = x_0\n",
    "    while error > tol:\n",
    "        y = q(x)\n",
    "        error = abs(x - y)\n",
    "        x = y\n",
    "        \n",
    "    return x\n",
    "\n",
    "newton(f, 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
